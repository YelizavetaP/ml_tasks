{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Функція втрат для логістичної регресії\n",
        "\n",
        "У логістичній регресії функція втрат (також відома як логістична функція втрат або бінарна крос-ентропія) визначається як:\n",
        "\n",
        "$$\n",
        "L(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
        "$$\n",
        "\n",
        "де:\n",
        "- $ m $ — кількість навчальних прикладів,\n",
        "- $ h_\\theta(x) $ — це гіпотеза моделі (логістична функція), яка визначається як:\n",
        "\n",
        "$$\n",
        "h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}\n",
        "$$\n",
        "\n",
        "### Похідні функції втрат для градієнтного спуску\n",
        "\n",
        "Для оптимізації параметрів $\\theta$ використовується градієнтний спуск. Необхідно знайти часткові похідні функції втрат $L(\\theta)$ за кожним параметром $\\theta_j$.\n",
        "\n",
        "#### Виведення похідних\n",
        "\n",
        "1. **Функція втрат**:\n",
        "\n",
        "$$\n",
        "L(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
        "$$\n",
        "\n",
        "2. **Похідна по $\\theta_j$**:\n",
        "\n",
        "Розглянемо похідну функції втрат по параметру $\\theta_j$:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L(\\theta)}{\\partial \\theta_j} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
        "$$\n",
        "\n",
        "3. **Похідна логістичної функції**:\n",
        "\n",
        "Знайдемо часткову похідну логістичної функції:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^{(i)}) = h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) x_j^{(i)}\n",
        "$$\n",
        "\n",
        "4. **Похідна логарифмів**:\n",
        "\n",
        "Похідна логарифма функції:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\theta_j} \\log(h_\\theta(x^{(i)})) = \\frac{1}{h_\\theta(x^{(i)})} \\cdot \\frac{\\partial h_\\theta(x^{(i)})}{\\partial \\theta_j} = \\frac{1}{h_\\theta(x^{(i)})} \\cdot h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) x_j^{(i)} = (1 - h_\\theta(x^{(i)})) x_j^{(i)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\theta_j} \\log(1 - h_\\theta(x^{(i)})) = \\frac{-1}{1 - h_\\theta(x^{(i)})} \\cdot \\frac{\\partial (1 - h_\\theta(x^{(i)}))}{\\partial \\theta_j} = \\frac{-1}{1 - h_\\theta(x^{(i)})} \\cdot (-h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) x_j^{(i)}) = -h_\\theta(x^{(i)}) x_j^{(i)}\n",
        "$$\n",
        "\n",
        "5. **Об'єднання похідних**:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L(\\theta)}{\\partial \\theta_j} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} (1 - h_\\theta(x^{(i)})) x_j^{(i)} + (1 - y^{(i)}) (-h_\\theta(x^{(i)})) x_j^{(i)} \\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} (1 - h_\\theta(x^{(i)})) x_j^{(i)} - (1 - y^{(i)}) h_\\theta(x^{(i)}) x_j^{(i)} \\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} x_j^{(i)} - y^{(i)} h_\\theta(x^{(i)}) x_j^{(i)} - h_\\theta(x^{(i)}) x_j^{(i)} + y^{(i)} h_\\theta(x^{(i)}) x_j^{(i)} \\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} x_j^{(i)} - h_\\theta(x^{(i)}) x_j^{(i)} \\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\frac{1}{m} \\sum_{i=1}^{m} \\left[ (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\right]\n",
        "$$\n",
        "\n",
        "Отже, часткова похідна функції втрат по параметру $\\theta_j$ для логістичної регресії виглядає так:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\right]\n",
        "$$\n",
        "\n",
        "Ця похідна використовується в градієнтному спуску для оновлення параметрів моделі:\n",
        "\n",
        "$$\n",
        "\\theta_j := \\theta_j - \\alpha \\frac{\\partial L(\\theta)}{\\partial \\theta_j}\n",
        "$$\n",
        "\n",
        "де $\\alpha$ - це швидкість навчання (learning rate)."
      ],
      "metadata": {
        "id": "47akk6cjtF4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mULFuu1tBRG"
      },
      "outputs": [],
      "source": []
    }
  ]
}