{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "PYcXOV5qentm"
      },
      "source": [
        "# Вступ у Deep Learning, основи PyTorch та лінійна регресія з нуля\n",
        "\n",
        "## Що таке Deep Learning?\n",
        "Глибоке навчання (deep learning) є підмножиною машинного навчання, яка використовує штучні нейронні мережі (artificial neural networks - ANNs) для обробки та аналізу інформації. Нейронні мережі складаються з обчислювальних вузлів (computational nodes), які розташовані шарами в алгоритмах глибинного навчання. Кожен шар містить вхідний шар (input layer), вихідний шар (output layer) та прихований шар (hidden layer). Нейронна мережа отримує навчальні дані, які допомагають алгоритму навчатися та покращувати точність. Коли нейронна мережа складається з трьох або більше шарів, вона вважається «глибокою» (deep), звідси й назва — глибинне навчання.\n",
        "\n",
        "![](https://yangxiaozhou.github.io/assets/cnn-covid-19/deep-nn.jpg)\n",
        "\n",
        " Основна відмінність між deep learning та класичним машинним навчанням полягає в тому, що в глибинному навчанні моделі автоматично виявляють важливі характеристики з великих обсягів даних, тоді як у машинному навчанні часто необхідно вручну вибирати та інженерити ознаки.\n",
        "\n",
        "![](https://cdn.prod.website-files.com/5fb24a974499e90dae242d98/60f6fcbbeb0b8f57a7980a98_5f213db7c7763a9288759ad1_5eac2d0ef117c236e34cc0ff_DeepLearning.jpeg)\n",
        "\n",
        "Алгоритми глибокого навчання натхненні роботою людського мозку. Принципи, за якими працюють алгоритми глибинного навчання, частково моделюються на основі того, як функціонує людський мозок. У мозку є мільярди нейронів, які з'єднані між собою і працюють разом для обробки інформації. Кожен нейрон отримує сигнали від інших нейронів і від зовнішнього середовища (з допомогою дендридів), обробляє їх і передає результати далі. Цей процес схожий на те, як працюють штучні нейронні мережі у глибинному навчанні.\n",
        "\n",
        "![](https://idiotdeveloper.com/wp-content/uploads/2020/05/1_SJPacPhP4KDEB1AdhOFy_Q.png)\n",
        "\n",
        "Штучні нейронні мережі складаються з \"штучних нейронів\" або обчислювальних вузлів, які імітують поведінку біологічних нейронів. Вони передають інформацію один одному через шари мережі (вхідні, приховані та вихідні шари), схоже на те, як нейрони в мозку передають сигнали. Кожен шар обробляє інформацію, робить висновки і передає їх на наступний шар, що дозволяє мережі навчатися й ухвалювати рішення на основі даних.\n",
        "\n",
        "Хоча штучні нейронні мережі не є точною копією роботи людського мозку, вони використовують цю біологічну аналогію для вирішення складних завдань, таких як розпізнавання зображень чи мовлення.\n",
        "\n",
        "![](https://neuwritesd.org/wp-content/uploads/2015/10/visual_stream_small.png)\n",
        "\n",
        "\n",
        "## Основні типи нейронних мереж в глибокому навчанні\n",
        " Глибоке навчання використовується в багатьох завданнях, які ми сьогодні вважаємо штучним інтелектом, включаючи розпізнавання зображень і мови, виявлення об'єктів (object detection) і обробку природної мови. Глибоке навчання може виявляти нелінійні, складні кореляції в наборах даних, хоча вимагає більше навчальних даних і обчислювальних ресурсів, ніж класичне машинне навчання.\n",
        "\n",
        "Деякі загальні типи нейронних мереж, які використовуються для глибинного навчання:\n",
        "\n",
        "- **Прямі нейронні мережі** (feedforward neural networks, FF) є одними з найстаріших форм нейронних мереж, у яких дані проходять в одному напрямку через шари штучних нейронів, доки не буде досягнуто результату.\n",
        "\n",
        "- **Рекурентні нейронні мережі** (recurrent neural networks, RNN) відрізняються від прямих тим, що зазвичай використовують **послідовні дані** (time series data) або дані, які містять послідовності. Рекурентні нейронні мережі мають «пам’ять» про те, що сталося на попередньому шарі, яка впливає на результат поточного шару.\n",
        "\n",
        "- **Довготривала/короткотривала пам'ять** (long/short term memory, LSTM) — це вдосконалена форма RNN, яка може використовувати пам’ять для «запам’ятовування» того, що сталося в попередніх шарах.\n",
        "\n",
        "- **Згорткові нейронні мережі** (convolutional neural networks, CNN) є одними з найпоширеніших у сучасному штучному інтелекті. Вони використовують кілька окремих шарів (згортковий шар, потім шар пулінгу), які фільтрують різні частини зображення, перш ніж зібрати його назад у повністю з'єднаному шарі (fully connected layer).\n",
        "\n",
        "- **Генеративно-змагальні мережі** (generative adversarial networks, GAN) передбачають змагання двох нейронних мереж (генератора та дискримінатора) одна проти одної, що в підсумку покращує точність результату.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvNLh4Nrjy_T"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "PyTorch — один із найпопулярніших фреймворків для побудови моделей deep learning. Його гнучкість і зручність у використанні роблять його ідеальним інструментом для дослідників та інженерів. PyTorch підтримує динамічну обчислювальну графи (dynamic computational graphs), що дозволяє легко експериментувати з архітектурою моделей і адаптувати їх під конкретні завдання, від комп'ютерного зору до обробки природної мови.\n",
        "\n",
        "Цей урок, натхнений [ноутбуками FastAI](https://github.com/fastai/fastai_v1/tree/master/dev_nb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu4GV4OXfNsS"
      },
      "source": [
        "Аби встановити pytorch - найкраще скористатись інструкціями на [сайті PyTorch](https://pytorch.org/get-started/locally/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo4tM0Jmezr_",
        "outputId": "60f73020-b7a6-4f0f-9e6e-45cd0dc373e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "7TDkWwGjentp"
      },
      "outputs": [],
      "source": [
        "# Імпорт Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "34f006aa7eb4bbc683c39b7059021da900180908",
        "id": "5YP40D1Sentq"
      },
      "source": [
        "## Тензори (Tensors) та градієнти (Gradients)\n",
        "\n",
        "Тензор - це число, вектор, матриця або будь-який n-вимірний масив."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "e22be3f71825128f990e78959fa00d1331d344e4",
        "id": "OYO-E0W6entq"
      },
      "outputs": [],
      "source": [
        "# Створюємо тензори\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "3cb90767ff9bc2c12b72548b1a430984241d4910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDN03Mqoentr",
        "outputId": "664aed7c-03eb-4dc0-9e7d-09ad8a4e2e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.)\n",
            "tensor(4., requires_grad=True)\n",
            "tensor(5., requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "66a939ee0ec472705acd3f23654bc3ccea1cc8b4",
        "id": "x4f2WLunentr"
      },
      "source": [
        "Ми можемо комбінувати тензори за допомогою звичайних арифметичних операцій."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "0bd8fdeb252742e3449b7a2f08bcb188645dc9cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9C9GkP-entr",
        "outputId": "fff42fd4-b6f5-42e3-d134-a827f821cc14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(17., grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Арифметичні операції\n",
        "y = w * x + b\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "64e0f175c65c3e875c671c40e4a9bf495e30b772",
        "id": "oZncPw1gents"
      },
      "source": [
        "Що робить PyTorch особливим, так це те, що ми можемо автоматично обчислювати похідну `y` по відношенню до тензорів, у яких `requires_grad` (вимагає градієнта) встановлено на `True`, тобто `w` та `b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "6c98996f00294f99eb11989b5a9ecdbda31864e1",
        "id": "ewyAUe00ents"
      },
      "outputs": [],
      "source": [
        "# Обчислюємо градієнти\n",
        "y.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "47a62ffb26a76329e511f9f063c4c26cc6a7dc21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lESwU8dvents",
        "outputId": "f67323c9-ba3f-431d-f768-8a836de7cc05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Виводимо градієнти\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLE4ZIfrqjsU"
      },
      "source": [
        "### Детальніше про параметр `requires_grad=True`\n",
        "\n",
        "Використання параметра `requires_grad=True` особливо важливо для процесу **backpropagation** (зворотного поширення помилки) у нейронних мережах.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/18870backprop2.png)\n",
        "\n",
        "#### Що це означає на практиці?\n",
        "Коли ви створюєте тензор з параметром `requires_grad=True`, PyTorch починає відстежувати всі операції з цим тензором, щоб потім, під час зворотного поширення, обчислити градієнти відносно цього тензора. Це дозволяє автоматично обчислювати похідні для навчання моделі, використовуючи оптимізатори для оновлення ваг на основі градієнтів.\n",
        "\n",
        "Розглянемо ще один приклад:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohVtp-1QqsWN",
        "outputId": "df40f326-0203-494b-a5b2-17dde48034b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 8., 10.])\n"
          ]
        }
      ],
      "source": [
        "# Створюємо тензор з requires_grad=True\n",
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "\n",
        "# Робимо кілька операцій\n",
        "y = x + 2\n",
        "z = y ** 2 # z = z(y) = z(y(x)) = y**2 = (x+2)**2 = x**2 + 2*2*x + 4\n",
        "result = z.sum()\n",
        "\n",
        "# Викликаємо зворотне поширення\n",
        "result.backward()\n",
        "\n",
        "# Отримуємо градієнти\n",
        "print(x.grad)  # це похідні функції result по x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE7_oUBX0zI_"
      },
      "source": [
        "dz(x)/dx = 2*x + 4\n",
        "\n",
        "x==2: 2*2 + 4 = 8\n",
        "\n",
        "x==3: 2*3 + 4 = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuRoGOHmqroQ"
      },
      "source": [
        "\n",
        "\n",
        "### Що відбувається:\n",
        "1. `x` — це тензор, для якого треба обчислювати градієнти (`requires_grad=True`).\n",
        "2. PyTorch автоматично будує **динамічний обчислювальний граф** (dynamic computational graph), відстежуючи всі операції з `x`.\n",
        "3. Функція `backward()` обчислює градієнти для кожного тензора, який має `requires_grad=True`.\n",
        "4. Градієнти зберігаються в атрибуті `grad` тензора `x`.\n",
        "\n",
        "Розберемося ще з математикою операцій.\n",
        "\n",
        "### По коду\n",
        "1. Ми створюємо тензор `x = torch.tensor([2.0, 3.0], requires_grad=True)`.\n",
        "2. Ми додаємо до `x` число 2:  \n",
        "   $ y = x + 2 = [4.0, 5.0] $.\n",
        "3. Потім підносимо `y` до квадрату:  \n",
        "   $ z = y^2 = [4.0^2, 5.0^2] = [16.0, 25.0] $.\n",
        "4. Ми знаходимо суму:  \n",
        "   $ result = 16.0 + 25.0 = 41.0 $.\n",
        "\n",
        "### Далі викликаємо `result.backward()`, щоб обчислити градієнти.\n",
        "\n",
        "Градієнти обчислюються через похідні функції `result` за значенням `x`.\n",
        "\n",
        "Похідна від функції $ f(x) = (x + 2)^2 $ виглядає так:\n",
        "\n",
        "1. Знайдемо похідну для кожного елемента $ x $:\n",
        "   $$\n",
        "   \\frac{d}{dx} (x + 2)^2 = 2 \\cdot (x + 2)\n",
        "   $$\n",
        "   \n",
        "2. Для першого елемента $ x = 2 $:\n",
        "   $$\n",
        "   \\frac{d}{dx} = 2 \\cdot (2 + 2) = 2 \\cdot 4 = 8\n",
        "   $$\n",
        "   \n",
        "3. Для другого елемента $ x = 3 $:\n",
        "   $$\n",
        "   \\frac{d}{dx} = 2 \\cdot (3 + 2) = 2 \\cdot 5 = 10\n",
        "   $$\n",
        "\n",
        "Отже, градієнти для тензора `x` будуть `[8.0, 10.0]`, що ви й бачите в результаті.\n",
        "\n",
        "Ці градієнти вказують, як зміна вхідного тензора `x` вплине на результат функції.\n",
        "\n",
        "\n",
        "### Коли **requires_grad=True** корисне?\n",
        "- Під час навчання моделей, коли потрібно оновлювати ваги на основі градієнтів.\n",
        "- У випадках, коли потрібно робити автоматичне диференціювання функцій для оптимізації.\n",
        "\n",
        "Якщо `requires_grad=False` (що є значенням за замовчуванням), для цього тензора градієнти не обчислюватимуться, і PyTorch не буде витрачати ресурси на побудову обчислювального графа.\n",
        "\n",
        "### Додаткові матеріали\n",
        "Детальніше про те, як працює backpropagation:\n",
        "- [конспект зі Stanford про BackProp](https://cs231n.stanford.edu/slides/2024/lecture_4.pdf)\n",
        "- [візуальний гайд](https://xnought.github.io/backprop-explainer/)\n",
        "- [відео-пояснення](https://youtu.be/IN2XmBhILt4?si=eZqFtVDJie3jmspx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0b65b6bb4d15127b1d51f09abf616cfd29fa48b4",
        "id": "pBvmONM9entt"
      },
      "source": [
        "## Формулювання проблеми"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c1beecda01bc332596edd193cade30006e3f6cbf",
        "id": "yp8d3S1Xentt"
      },
      "source": [
        "Ми створимо модель, яка прогнозує врожайність яблук та апельсинів (*цільові змінні*), аналізуючи середню температуру, опади та вологість (*вхідні змінні або ознаки*) в регіоні. Ось навчальні дані:\n",
        "\n",
        "<img src=\"https://i.imgur.com/lBguUV9.png\" width=\"500\" />\n",
        "\n",
        "У моделі **лінійної регресії** (linear regression) кожна цільова змінна оцінюється як зважена сума вхідних змінних, зсунута на деяку константу, відому як зсув (bias):\n",
        "\n",
        "```\n",
        "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yeild_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Візуально це означає, що врожайність яблук є лінійною або площинною функцією температури, опадів та вологості.\n",
        "\n",
        "<img src=\"https://i.imgur.com/mtkR2lB.png\" width=\"540\" >\n",
        "\n",
        "Запишемо також нашу формулу у матричному форматі\n",
        "\n",
        "Нехай:\n",
        "\n",
        "- $ Y = \\begin{bmatrix} \\text{yield_apple} \\\\ \\text{yield_orange} \\end{bmatrix} $ — вектор виходів (врожайність яблук та апельсинів),\n",
        "- $ W = \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\end{bmatrix} $ — матриця ваг (коефіцієнтів моделі),\n",
        "- $ X = \\begin{bmatrix} \\text{temp} \\\\ \\text{rainfall} \\\\ \\text{humidity} \\end{bmatrix} $ — вектор вхідних змінних (температура, кількість опадів, вологість),\n",
        "- $ B = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix} $ — вектор зміщень (bias).\n",
        "\n",
        "Тоді матричне рівняння буде:\n",
        "\n",
        "$$\n",
        "Y = W \\cdot X + B = X \\cdot W^T + B\n",
        "$$\n",
        "\n",
        "Або більш детально:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix} \\text{yield_apple} \\\\ \\text{yield_orange} \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\end{bmatrix} \\cdot \\begin{bmatrix} \\text{temp} \\\\ \\text{rainfall} \\\\ \\text{humidity} \\end{bmatrix} + \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Ця форма показує, як обчислюється кожний результат (врожайність) через лінійну комбінацію ваг і вхідних змінних з додаванням зміщення.\n",
        "\n",
        "**Наша мета**: Знайти пасучий набір *ваг* (weights) та *зсувів* (biases) за допомогою навчальних даних, щоб зробити точні прогнози."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c24b8195c0e9c6e8e13e169d264484f1f9b3b1ae",
        "id": "rpve_1Bcentt"
      },
      "source": [
        "## Навчальні дані\n",
        "Навчальні дані можна представити за допомогою 2 матриць (inputs та targets), кожна з яких має один рядок на спостереження та один стовпець на змінну."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "dfda99005fc6daf3a49ae1cdd427ccac0aa446b1",
        "id": "UpWmZrsyentt"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "bf56faf74f7e29c9ed7523308718a9ab1acc0667",
        "id": "cBi2BDqOentt"
      },
      "outputs": [],
      "source": [
        "# Таргети (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "70d48f83ae4fce7aba7dd78fd58dddc77c598bfd",
        "id": "zkhhyk4lentu"
      },
      "source": [
        "Перед тим, як побудувати модель, нам потрібно перетворити вхідні дані та цілі на тензори (tensors) PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "931c1bad8788e607fa100d4338e1b1fe120e2339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBE6NQvkentu",
        "outputId": "eed5c03c-bf66-40c8-a210-6fb3fa8dfb4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "# Перетворення вхідних даних і цілей у тензори\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "652647cd90bd0784ec4dc53472410f7358ee18c9",
        "id": "izyVEa6Kentu"
      },
      "source": [
        "## Модель лінійної регресії (from scratch)\n",
        "\n",
        "*Ваги* (weights) та *зсуви* (biases) також можуть бути представлені у вигляді матриць, ініціалізованих випадковими значеннями. Перший рядок `w` та перший елемент `b` використовуються для прогнозування першої цільової змінної, тобто врожайності яблук, а аналогічно другий - для апельсинів."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "6f788ae559355b3f01667be1554a5d2bdcade8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLEjxyBHentu",
        "outputId": "e06d0d27-3387-4f33-fafd-86bdc6b8919e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.8019, -0.2081, -0.1651],\n",
            "        [ 0.8481,  1.8359,  0.7972]], requires_grad=True)\n",
            "tensor([0.5586, 0.5369], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3579a065997cae41f7f504916b6bc07878ac768c",
        "id": "ZZ2ZhP-hentu"
      },
      "source": [
        "*Модель* - це просто функція, яка виконує множення матриць вхідних даних `x` та ваг (weights) `w` (транспонованих) і додає зсув (bias) `b` (реплікований для кожного спостереження)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b1119f5ae9688a5f31dba438c7f78ca382deb7e3",
        "id": "kQ8aLc4Qentu"
      },
      "outputs": [],
      "source": [
        "# Визначаємо модель\n",
        "def model(x, w, b):\n",
        "    return x @ w.t() + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDcCaBlLSr1V"
      },
      "source": [
        "Цей код визначає модель лінійної регресії, де реалізується матричне множення вхідних даних на транспоновану матрицю ваг, з подальшим додаванням зміщення.\n",
        "\n",
        "**Оператор `@`:**\n",
        "У Python оператор `@` використовується для матричного множення. У цьому випадку це означає, що ми множимо вхідні дані `x` на матрицю ваг `w`.\n",
        "\n",
        "**`w.t()`**:\n",
        "Це виклик методу `.t()`, який транспонує матрицю ваг `w`. Транспонування змінює розміри матриці, що необхідно для правильного матричного множення. Наприклад, якщо `w` має розміри (2, 3), то після транспонування воно матиме розміри (3, 2), що дозволяє коректно перемножити на вектор або матрицю `x`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8e0a4644cb1c4ed68a3bcf67a8a156341ac7c853",
        "id": "4weGJ4krentu"
      },
      "source": [
        "Матриця, отримана шляхом передачі вхідних даних до моделі, є набором прогнозів для цільових змінних."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b042a3cf8f16f4c4380cccbac9d0892719c24190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rveODWosentv",
        "outputId": "93805e85-600e-4c07-9abb-04844a36693b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -79.0244,  219.7365],\n",
            "        [-101.2965,  290.2986],\n",
            "        [-106.6718,  366.5751],\n",
            "        [ -96.2941,  195.4864],\n",
            "        [ -86.3102,  291.1108]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Генеруємо передбачення\n",
        "preds = model(inputs, w, b)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "5551ef933de7902c8b5a38ae3d8e4795cb244f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DUDVri-entv",
        "outputId": "c052ac84-23c1-4543-df37-03ea83a67276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "# Порівняємо з таргетами\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2c4a9cf2b3c9152f2f832176bce9a87381e2419c",
        "id": "k6hqPViqentv"
      },
      "source": [
        "Оскільки ми почали з випадкових ваг (weights) і зсувів (biases), модель не дуже добре справляється з прогнозуванням цільових змінних."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "edaae7266f5d47c5e970e1438a812f10d8d35fb4",
        "id": "3NB5kfx8entv"
      },
      "source": [
        "## Функція втрат\n",
        "\n",
        "Ми вже знайомі з тим, що таке фукнція втрат.\n",
        "\n",
        "Ми можемо порівняти прогнози з фактичними цілями, використовуючи наступний метод:\n",
        "* Обчислимо різницю між двома матрицями (`preds` і `targets`).\n",
        "* Піднесемо до квадрату всіх елементів матриці різниці, щоб усунути негативні значення.\n",
        "* Обчислимо середнє значення елементів в отриманій матриці.\n",
        "\n",
        "Результат - це одне число, відоме як **середня квадратична помилка** (mean squared error, MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "dbf5bca8cbf2a3831089b454c70469e3748e9682",
        "id": "xIMLhrfsentv"
      },
      "outputs": [],
      "source": [
        "# MSE loss\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "90da6779aad81608c40cdca77c3c04b68a815c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67EGJNgWentv",
        "outputId": "89220137-286b-45d9-a01c-60df0a0e508c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(31977.5586, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Обчислимо loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3ab3acadf389f30430b55c26c7979dcffaa974a5",
        "id": "Y4985xoKentv"
      },
      "source": [
        "Ми отримали наші **втрати** (loss), тобто міру того, наскільки погано модель передбачає цільові змінні. Памʼятаємо, що чим нижча втрата, тим краща модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c61acf9c3cff205d769fc52ed3b1b76f5ae66233",
        "id": "86sK17T6entv"
      },
      "source": [
        "## Обчислення градієнтів\n",
        "\n",
        "![](https://i.sstatic.net/7Ui1C.png)\n",
        "\n",
        "З PyTorch ми можемо автоматично обчислити градієнт або похідну `loss` (втрати) відносно ваг (weights) і зсувів (biases), оскільки у них встановлено `requires_grad` в `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ef66710c6ef1944567c4dc033e1ca316f35490ab",
        "id": "LOjVlX48entw"
      },
      "outputs": [],
      "source": [
        "# Обчислимо gradients\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KveQeW99sfA7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6504cddcfb4bfb0817bf03ef460f08f3145a9091",
        "id": "T3pb0FEDentw"
      },
      "source": [
        "Градієнти зберігаються у властивості `.grad` відповідних тензорів."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "5943d1cef604a178c95f5e8d255519d42d9f9982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGiYPLV-entw",
        "outputId": "e4100c65-9890-4ac0-f350-2695f6b5ee33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.8019, -0.2081, -0.1651],\n",
            "        [ 0.8481,  1.8359,  0.7972]], requires_grad=True)\n",
            "tensor([[-14241.5215, -15717.8330,  -9638.1152],\n",
            "        [ 15303.8467,  16265.4502,  10002.5791]])\n"
          ]
        }
      ],
      "source": [
        "# Градієнти вагів\n",
        "print(w)\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "47278e318b156c6a5812e0842dbc4164c8362562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9emLgTDentw",
        "outputId": "298aed0e-5303-4338-845e-139b63db44d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5586, 0.5369], requires_grad=True)\n",
            "tensor([-170.1194,  180.6415])\n"
          ]
        }
      ],
      "source": [
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "466dc3a2cc2d4bd2c10ae4cf59cf4627b5cc9c75",
        "id": "ptntWxjZentw"
      },
      "source": [
        "Ключове усвідомлення з математичного аналізу полягає в тому, що градієнт вказує на швидкість зміни втрат, або нахил функції втрат відносно ваг (weights) і зсувів (biases).\n",
        "\n",
        "* Якщо елемент градієнта **позитивний**,\n",
        "    * **збільшення** значення елемента трохи **збільшить** втрати.\n",
        "    * **зменшення** значення елемента трохи **зменшить** втрати.\n",
        "\n",
        "<img src=\"https://i.imgur.com/2H4INoV.png\" width=\"400\" />\n",
        "\n",
        "* Якщо елемент градієнта **негативний**,\n",
        "    * **збільшення** значення елемента трохи **зменшить** втрати.\n",
        "    * **зменшення** значення елемента трохи **збільшить** втрати.\n",
        "\n",
        "<img src=\"https://i.imgur.com/h7E2uAv.png\" width=\"400\" />    \n",
        "\n",
        "Збільшення або зменшення пропорційне значенню градієнта."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "35ed968bfc135bd44eeb100ae401d0628fbc5c63",
        "id": "teI9mMI1entw"
      },
      "source": [
        "Нарешті, ми обнулимо градієнти перед продовженням, оскільки PyTorch накопичує градієнти."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "5f02dc376c21857d4e545d98413952c5ac73039b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M5Y8vaVentw",
        "outputId": "9fb7700d-14bc-430c-9a38-0ccc249661e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ],
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5501c66c9729c4954e9b798a0634a9d84487e639",
        "id": "UCZzsIm5entw"
      },
      "source": [
        "## Налаштування ваг і зсувів за допомогою градієнтного спуску\n",
        "\n",
        "Ми зменшимо втрати та покращимо нашу модель, використовуючи алгоритм градієнтного спуску (gradient descent), який має такі кроки:\n",
        "\n",
        "1. Генерація прогнозів\n",
        "2. Обчислення втрат\n",
        "3. Обчислення градієнтів (gradients) відносно ваг і зсувів\n",
        "4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту\n",
        "5. Скидання градієнтів на нуль"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ef0d2bd2d9c5acb60992e238439ee00c2223319f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX1A97wBentw",
        "outputId": "4338012a-8890-448a-9b71-18b62f0182ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -79.0244,  219.7365],\n",
            "        [-101.2965,  290.2986],\n",
            "        [-106.6718,  366.5751],\n",
            "        [ -96.2941,  195.4864],\n",
            "        [ -86.3102,  291.1108]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Генеруємо передбачення\n",
        "preds = model(inputs, w, b)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "302ee8226da4ee5d0dad137c638573a79f8abded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPk6lOjxent0",
        "outputId": "56815f76-03f0-4a64-b54f-da90ab08a2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(31977.5586, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Обчислюємо loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "01c596aecf87e4670033ddd4ed36e26b97e2f9ab",
        "id": "ehR2iazyent1"
      },
      "outputs": [],
      "source": [
        "# Обчислюємо градієнти\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ec1e2bdc8f91523e556fad55ee8c01eb5431ae24",
        "id": "sQRshl9fent1"
      },
      "outputs": [],
      "source": [
        "# Оновлюємо ваги і ресетимо градієнти\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUBom6vhUdod"
      },
      "source": [
        "Конструкція `with torch.no_grad():` використовується в PyTorch для відключення автоматичного відстеження градієнтів у контексті виконуваних операцій. Вона потрібна для випадків, коли ви не хочете, щоб PyTorch зберігав інформацію про операції для обчислення градієнтів, наприклад, коли ви оновлюєте ваги моделі вручну або робите інші обчислення, що не потребують диференціювання.\n",
        "\n",
        "### Пояснення:\n",
        "\n",
        "1. **Оновлення ваг:**\n",
        "   У цьому фрагменті коду виконується ручне оновлення ваг (`w` і `b`) після обчислення градієнтів. У процесі навчання моделі ви спочатку обчислюєте градієнти для ваг, а потім використовуєте ці градієнти для оновлення самих ваг. Оскільки операції оновлення ваг не повинні брати участь у диференціюванні (вони не впливають на зворотне поширення помилки), відстежувати градієнти в цьому процесі немає сенсу.\n",
        "\n",
        "   Тому конструкція `with torch.no_grad():` забезпечує, що операції, які виконуються всередині цього блоку (оновлення ваг і зміщень), **не будуть записані в обчислювальний граф**, а градієнти для цих операцій не будуть обчислюватися.\n",
        "\n",
        "2. **Обнулення градієнтів:**\n",
        "   Після оновлення ваг, градієнти для `w` і `b` очищаються методом `.zero_()`, щоб вони не накопичувалися на наступних етапах навчання. Це важливо, оскільки кожного разу, коли ви викликаєте `.backward()` для обчислення градієнтів, значення градієнтів додаються до вже існуючих. Якщо їх не обнуляти, старі градієнти впливатимуть на нові значення.\n",
        "\n",
        "### Чому це важливо:\n",
        "Без використання `torch.no_grad()` операції оновлення ваг також включалися б в обчислювальний граф, що призвело б до непотрібних витрат пам'яті та ресурсів. Це не тільки вповільнило б обчислення, але й могло б викликати небажані побічні ефекти під час навчання.\n",
        "\n",
        "Отже, блок `with torch.no_grad():` гарантує, що операції оновлення ваг відбуваються **ефективно** і без залучення градієнтних обчислень."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "1d61b6f61f49b19099d29d1be8ec5ae4967bbd51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ABNHI9ent1",
        "outputId": "eaa469ee-2daf-46a3-ada9-45f8505a2680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.6595, -0.0509, -0.0687],\n",
            "        [ 0.6951,  1.6733,  0.6972]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6af10c29db7cb0d6e869b2c30966a34a48a011e2",
        "id": "bZ6eNa3Rent1"
      },
      "source": [
        "З новими вагами (weights) та зсувами (biases) модель повинна мати менші втрати (loss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "c542b5fe75d82454f34cac13cdcff8b48dd1945c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSD_2HQpent1",
        "outputId": "fb58a5e3-2e8b-41e8-d295-f8f969956801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(21583.2852, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Обчислюємо loss\n",
        "preds = model(inputs, w, b)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5201901695f3ea13d7fdd5d985da7e0761c541d0",
        "id": "4K6ZlaUSent1"
      },
      "source": [
        "## Тренування протягом кількох епох\n",
        "\n",
        "Щоб ще більше зменшити втрати, ми повторюємо процес налаштування ваг і зсувів, використовуючи градієнти, кілька разів. Кожна ітерація в тренування нейронних мереж називається епохою (epoch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "9f5f0ffeee666b30c5828636359f0be6addbef7c",
        "id": "_LaxHxYment1"
      },
      "outputs": [],
      "source": [
        "# Тренування протягом 100 епох\n",
        "for i in range(100):\n",
        "    preds = model(inputs, w, b)\n",
        "    loss = mse(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "c4820ca48b78f4dc242d80a9ec3ec6aca1aef671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSiNr5S8ent1",
        "outputId": "8cf8b7f4-6826-46fd-a298-def63f2d5c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(46.0941, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Обчислюємо loss\n",
        "preds = model(inputs, w, b)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "bbcd65fa7094cec187565e54c2107e683bea787b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6trXN6Kent1",
        "outputId": "c3e7005d-60c3-4197-9f1a-a2c4c298fe18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 59.3792,  71.7505],\n",
              "        [ 81.7081,  96.7536],\n",
              "        [116.2700, 139.5503],\n",
              "        [ 33.1978,  44.3887],\n",
              "        [ 94.0937, 108.1253]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "addec2c4eca8edfcae5544ea2cc717182c21d90f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F-l1IRwent2",
        "outputId": "2f377acf-e0e8-4110-9159-0994dddfa083"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvzTg6PCU7jc"
      },
      "source": [
        "Вийшли доволі непогані передбачення.\n",
        "Хорошою практикою вважається - спробувати заоверфітити модель на кількох точках аби перевірити, що вона тренується та потенційно збігаєтсья (досягнає мінімума функції втрат). Але ця вже точно бачимо, що тренується."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ecc6e79cdfb6a8ca882895ccc895b61b960b0a04",
        "id": "Xbv1Vx1Went2"
      },
      "source": [
        "## Модель лінійної регресії з використанням вбудованих функцій PyTorch\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ce66cf0d09a3f38bf2f00ea40418c56d98f1f814",
        "id": "dvqx91xoent2"
      },
      "outputs": [],
      "source": [
        "# Імпортуємо модуль nn\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "74bb18bd01ac809079eeb8d05695206e8ba02069",
        "id": "SBv7tbmwent2"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples, oranges)\n",
        "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],\n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119],\n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "d94b355f55250e9c7dcff668920f02d7c5c04925",
        "id": "qRz9uTSsent2"
      },
      "outputs": [],
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-kRfFwUVPs4",
        "outputId": "28f0818e-4c15-4d6b-a447-a91b981ef3f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.]])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a0665466eb5401f40a816b323a34450b2c052c41",
        "id": "yB1kzJ2rent2"
      },
      "source": [
        "### Набір даних та DataLoader\n",
        "\n",
        "Ми створимо `TensorDataset`, який дозволяє отримувати доступ до рядків з `inputs` та `targets` у вигляді кортежів. Ми також створимо DataLoader, щоб розділити дані на партії (batches) під час навчання. Він також надає інші утиліти, такі як перемішування (shuffling) та вибірка (sampling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "206f5fd0473386476b23477bf38d2c327b6376c9",
        "id": "fY2IMPUoent2"
      },
      "outputs": [],
      "source": [
        "# Імпортуємо tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "c47a4f2f86fda3918094e01cf7ab0698bbb5acc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ra8exGbent3",
        "outputId": "100ad601-dc90-4efc-fb4d-fceee89469f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]),\n",
              " tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Визначаємо dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "0a2f69126319d738b82ae67d5d404ecd6161bfac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s74br0C8ent3",
        "outputId": "1b7ed666-9895-4d09-dcdc-f404fc569be1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[ 91.,  88.,  64.],\n",
              "         [ 73.,  67.,  43.],\n",
              "         [ 87., 134.,  58.],\n",
              "         [ 69.,  96.,  70.],\n",
              "         [ 87., 134.,  58.]]),\n",
              " tensor([[ 81., 101.],\n",
              "         [ 56.,  70.],\n",
              "         [119., 133.],\n",
              "         [103., 119.],\n",
              "         [119., 133.]])]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Визначаємо data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "next(iter(train_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "276a262e1b9e3a048bcd32989013f9c501c59037",
        "id": "cciAwvEkent3"
      },
      "source": [
        "### nn.Linear\n",
        "Замість того, щоб вручну ініціалізувати ваги та зміщення, ми можемо визначити модель, використовуючи `nn.Linear`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "59da3506559a0640d80d18f77b02726a1757be2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIlGbSYaent3",
        "outputId": "0475f311-a0fd-491b-cbda-3582572dfce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.5374,  0.4882, -0.0646],\n",
            "        [-0.4105, -0.4314, -0.2982]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0749, 0.0677], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Визначаємо модель\n",
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b3a4a8c499a4680f2533329712de034671dd1cdd",
        "id": "Zw0NxB4Cent3"
      },
      "source": [
        "### Оптимізатор\n",
        "Замість того, щоб вручну маніпулювати вагами та зміщеннями, використовуючи градієнти, ми можемо використовувати оптимізатор `optim.SGD` - це як раз використання градієнтного спуску."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "1848398bd1ced8c25a7bb55612cf32a774500280",
        "id": "lG9EvalUent3"
      },
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "28cbe62be55010bd11b31d819cff38da5a772b18",
        "id": "6TSZ8doVent3"
      },
      "source": [
        "### Функція втрат\n",
        "Замість того, щоб визначати функцію втрат вручну, ми можемо використовувати вбудовану функцію втрат `mse_loss`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "69d7f4e8e27ccd077f711da27f8bede8aa711893",
        "id": "XKEsDH2yent3"
      },
      "outputs": [],
      "source": [
        "# Імпортуємо nn.functional\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "a02ff888ed4be720fd9ca376022d8fdcf2559683",
        "id": "8bQKH34uent4"
      },
      "outputs": [],
      "source": [
        "# Визначаємо loss функцію\n",
        "loss_fn = F.mse_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "a540adf76725ea9968025f6c029fdd251bdada6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E80f7oBGent4",
        "outputId": "27d02200-a8ce-4a69-fe93-f5cc16262747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(17683.6211, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e833614a69ff18c554a3d89f643ae2f11e0260f6",
        "id": "8Nm_yDFNent4"
      },
      "source": [
        "### Навчання моделі\n",
        "\n",
        "Ми готові навчити модель. Ми можемо визначити функцію `fit`, яка навчає модель протягом заданої кількості епох."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "128bc7260221f5338edf8b503c75f0c7d1cce7e8",
        "id": "f8dhEVvcent4"
      },
      "outputs": [],
      "source": [
        "# Визначаэмо функцію для навчання моделі\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            # Створення передбачень\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконання градієнтного спуску\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "    print('Training loss: ', loss_fn(model(inputs), targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPUEoOIQielJ"
      },
      "outputs": [],
      "source": [
        "# Модифікована функцію fit для відстеження втрат\n",
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Ініціалізуємо акумулятор для втрат\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            # Генеруємо передбачення\n",
        "            pred = model(xb)\n",
        "\n",
        "            # Обчислюємо втрати\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконуємо градієнтний спуск\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Накопичуємо втрати\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Обчислюємо середні втрати для епохи\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Виводимо підсумок епохи\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ae8ca4686cf6a68f6c9ca93bf3d227abe96c2201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLW9fOmkent4",
        "outputId": "d618f2cd-df14-424e-e4ca-3ed30889722e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/400], Loss: 428.3169\n",
            "Epoch [20/400], Loss: 291.4395\n",
            "Epoch [30/400], Loss: 209.3873\n",
            "Epoch [40/400], Loss: 169.2091\n",
            "Epoch [50/400], Loss: 115.7236\n",
            "Epoch [60/400], Loss: 89.7449\n",
            "Epoch [70/400], Loss: 71.3112\n",
            "Epoch [80/400], Loss: 54.8442\n",
            "Epoch [90/400], Loss: 45.9740\n",
            "Epoch [100/400], Loss: 38.2814\n",
            "Epoch [110/400], Loss: 32.9952\n",
            "Epoch [120/400], Loss: 29.1761\n",
            "Epoch [130/400], Loss: 28.3723\n",
            "Epoch [140/400], Loss: 23.9115\n",
            "Epoch [150/400], Loss: 23.1477\n",
            "Epoch [160/400], Loss: 20.2759\n",
            "Epoch [170/400], Loss: 19.1617\n",
            "Epoch [180/400], Loss: 17.6004\n",
            "Epoch [190/400], Loss: 16.6515\n",
            "Epoch [200/400], Loss: 15.5396\n",
            "Epoch [210/400], Loss: 15.5817\n",
            "Epoch [220/400], Loss: 14.4443\n",
            "Epoch [230/400], Loss: 13.1248\n",
            "Epoch [240/400], Loss: 12.6209\n",
            "Epoch [250/400], Loss: 11.9686\n",
            "Epoch [260/400], Loss: 11.1039\n",
            "Epoch [270/400], Loss: 11.1012\n",
            "Epoch [280/400], Loss: 9.9027\n",
            "Epoch [290/400], Loss: 9.6864\n",
            "Epoch [300/400], Loss: 8.9101\n",
            "Epoch [310/400], Loss: 8.4269\n",
            "Epoch [320/400], Loss: 8.1060\n",
            "Epoch [330/400], Loss: 7.7471\n",
            "Epoch [340/400], Loss: 7.3448\n",
            "Epoch [350/400], Loss: 6.9410\n",
            "Epoch [360/400], Loss: 6.9016\n",
            "Epoch [370/400], Loss: 6.1314\n",
            "Epoch [380/400], Loss: 6.2051\n",
            "Epoch [390/400], Loss: 5.7595\n",
            "Epoch [400/400], Loss: 5.5831\n"
          ]
        }
      ],
      "source": [
        "# Train the model for 100 epochs\n",
        "loss = fit_return_loss(400, model, loss_fn, opt, train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "osJSPvuijOe3",
        "outputId": "1a140771-eb07-4792-e0aa-f4aaf6ba24da"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "32588a47d0478772a1f08fa55874a322630bd0b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv7rrJKoent4",
        "outputId": "adaf5bff-a9b0-454b-9914-3453c7fb6af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 57.3280,  70.4553],\n",
              "        [ 80.4752,  99.2248],\n",
              "        [122.0473, 135.7823],\n",
              "        [ 22.0299,  37.8183],\n",
              "        [ 98.3917, 116.1860],\n",
              "        [ 57.3280,  70.4553],\n",
              "        [ 80.4752,  99.2248],\n",
              "        [122.0473, 135.7823],\n",
              "        [ 22.0299,  37.8183],\n",
              "        [ 98.3917, 116.1860],\n",
              "        [ 57.3280,  70.4553],\n",
              "        [ 80.4752,  99.2248],\n",
              "        [122.0473, 135.7823],\n",
              "        [ 22.0299,  37.8183],\n",
              "        [ 98.3917, 116.1860]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugsb3CGxjz7V",
        "outputId": "65e253e7-530d-477f-910e-1cd1171bc535"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 57,  70],\n",
              "        [ 80,  99],\n",
              "        [122, 135],\n",
              "        [ 22,  37],\n",
              "        [ 98, 116],\n",
              "        [ 57,  70],\n",
              "        [ 80,  99],\n",
              "        [122, 135],\n",
              "        [ 22,  37],\n",
              "        [ 98, 116],\n",
              "        [ 57,  70],\n",
              "        [ 80,  99],\n",
              "        [122, 135],\n",
              "        [ 22,  37],\n",
              "        [ 98, 116]], dtype=torch.int32)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds.int()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "12d757c0f37c2e3af65cf9d4b59878cc10c65acf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfVyaBozent4",
        "outputId": "1ff613a7-91e0-4880-d728-2d5b986a522e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compare with targets\n",
        "targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e182289ebf21d8296f11f13264c4732c100da14f",
        "id": "gU_tYu39ent5"
      },
      "source": [
        "# Feed-Forward Neural Networks\n",
        "\n",
        "![ffnn](https://afit-r.github.io/public/images/analytics/deep_learning/deep_nn.png)\n",
        "\n",
        "**Feedforward Neural Networks (FFNN)** або прямі нейронні мережі — це один із найпростіших і найпоширеніших типів штучних нейронних мереж, що використовується в багатьох додатках машинного навчання, включаючи класифікацію, регресію та інші завдання. Вони є важливою базою для більш складних моделей, таких як згорткові (CNN) та рекурентні (RNN) нейронні мережі.\n",
        "\n",
        "### Як працюють Feedforward Neural Networks?\n",
        "\n",
        "Основна ідея FFNN полягає в тому, що інформація передається лише в одному напрямку: від входу (input) до виходу (output). Це відрізняє їх від рекурентних нейронних мереж, де дані можуть \"зворотно\" впливати на наступні обчислення.\n",
        "\n",
        "#### Структура FFNN:\n",
        "1. **Вхідний шар (Input Layer):** В цьому шарі нейрони отримують дані із зовнішнього середовища. Кожен нейрон відповідає за окрему характеристику вхідних даних.\n",
        "   \n",
        "2. **Приховані шари (Hidden Layers):** Це шари, які не мають прямого зв'язку із зовнішнім світом. Нейрони прихованих шарів виконують нелінійні перетворення на основі вхідних даних, що допомагає моделі виявляти складні закономірності. У складних моделях може бути кілька прихованих шарів, що робить мережу \"глибокою\".\n",
        "\n",
        "3. **Вихідний шар (Output Layer):** Нейрони цього шару генерують результати моделі. У випадку класифікації вихід може представляти ймовірності належності до різних класів; у випадку регресії — передбачувані значення.\n",
        "\n",
        "### Як працює FFNN:\n",
        "\n",
        "1. **Перетворення вхідних даних:**\n",
        "   Кожен нейрон у прихованих шарах отримує вхідні дані, які є лінійною комбінацією значень із попереднього шару, зважених відповідними вагами. Для кожного нейрона обчислюється:\n",
        "\n",
        "   $$\n",
        "   z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\dots + w_n \\cdot x_n + b\n",
        "   $$\n",
        "\n",
        "   Де:\n",
        "   - $_1, x_2, \\dots, x_n$ — вхідні значення,\n",
        "   - $w_1, w_2, \\dots, w_n$ — ваги нейрона,\n",
        "   - $b$ — зміщення (bias),\n",
        "   - $z$ — активація нейрона.\n",
        "\n",
        "2. **Активаційна функція:**\n",
        "   Після обчислення лінійної комбінації значень застосовується **активаційна функція**, яка додає нелінійність до моделі. Це може бути функція ReLU (Rectified Linear Unit), сигмоподібна або інша функція, що дозволяє моделі навчатися складним і нелінійним закономірностям.\n",
        "\n",
        "   $$\n",
        "   a = f(z)\n",
        "   $$\n",
        "\n",
        "   Де $ f(z) $ — це активаційна функція.\n",
        "\n",
        "\n",
        "  <img src=\"https://cdn-images-1.medium.com/max/1600/1*XxxiA0jJvPrHEJHD4z893g.png\" width=\"640\">\n",
        "\n",
        "3. **Передача інформації далі:**\n",
        "   Вихід кожного нейрона передається до наступного шару, де процес повторюється. Інформація йде послідовно від вхідного шару до вихідного шару, поки не буде згенерований остаточний результат.\n",
        "\n",
        "### Основна відмінність від лінійної регресії:\n",
        "- **Лінійна регресія** працює з лінійними залежностями між вхідними та вихідними змінними, тоді як FFNN може обробляти **нелінійні взаємозв'язки** завдяки використанню прихованих шарів і нелінійних активаційних функцій.\n",
        "- Лінійна регресія має лише один шар (вхідний і вихідний), тоді як FFNN складається з кількох шарів.\n",
        "\n",
        "### Використання:\n",
        "Feedforward Neural Networks можуть бути застосовані для вирішення різноманітних задач:\n",
        "- **Класифікація зображень**\n",
        "- **Аналіз тексту**\n",
        "- **Розпізнавання мовлення**\n",
        "- **Передбачення в часових рядах**\n",
        "\n",
        "### Недоліки:\n",
        "Основний недолік FFNN — це те, що вони не мають \"пам'яті\", оскільки інформація передається лише в одному напрямку, що обмежує їхню ефективність при роботі з послідовними даними, де важлива інформація з попередніх станів. Для таких задач краще використовувати рекурентні нейронні мережі (RNN) або їх варіації, такі як LSTM.\n",
        "\n",
        "Таким чином, **Feedforward Neural Networks** — це базовий, але потужний інструмент для вирішення багатьох задач, який дозволяє обробляти як прості, так і складні взаємозв'язки у даних.\n",
        "\n",
        "--------------\n",
        "Щоб використовувати fast-forward нейронну мережу замість лінійної регресії, ми можемо розширити (визначити новий з допомогою наслідування) клас `nn.Module` з PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "c405e5075d6c4adb26ead75c17be90eaeb43f2d5",
        "id": "nYcLCv02ent5"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    # Initialize the layers\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(3, 3)\n",
        "        self.act1 = nn.ReLU() # Activation function\n",
        "        self.linear2 = nn.Linear(3, 2)\n",
        "\n",
        "    # Perform the computation\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2448d9832722f4f2813f8bd80b91daefd901dc2e",
        "id": "Tlf-QtCJent5"
      },
      "source": [
        "Тепер ми можемо визначити модель, оптимізатор (optimizer) та функцію втрат (loss function) точно так само, як і раніше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "a51ca222c2ea037c3caccaeab98ccdbcc30800cf",
        "id": "rtCcxYrqent5"
      },
      "outputs": [],
      "source": [
        "model = SimpleNet()\n",
        "opt = torch.optim.SGD(model.parameters(), 1e-5)\n",
        "loss_fn = F.mse_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "21000c9739ea39a173a256f87339bfc112c1a9b0",
        "id": "Xj7wQrOfent5"
      },
      "source": [
        "Нарешті, ми можемо застосувати градієнтний спуск (gradient descent) для навчання моделі, використовуючи ту ж функцію `fit`, яка була визначена раніше для лінійної регресії.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "e94de6868c76803a998c1c1934ed229c826f3b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTrJKvPBent5",
        "outputId": "d44db22d-6f29-4cb0-eace-2eac4559404b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 3484.2894\n",
            "Epoch [20/100], Loss: 176.8163\n",
            "Epoch [30/100], Loss: 138.1754\n",
            "Epoch [40/100], Loss: 116.1143\n",
            "Epoch [50/100], Loss: 98.2445\n",
            "Epoch [60/100], Loss: 80.2569\n",
            "Epoch [70/100], Loss: 74.5938\n",
            "Epoch [80/100], Loss: 68.2467\n",
            "Epoch [90/100], Loss: 65.1691\n",
            "Epoch [100/100], Loss: 58.1829\n"
          ]
        }
      ],
      "source": [
        "loss = fit_return_loss(100, model, loss_fn, opt, train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcBMkPEWi_2",
        "outputId": "2deec2a4-3d91-437e-c2c8-581bc3d87dfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 59,  70],\n",
              "        [ 80,  94],\n",
              "        [124, 146],\n",
              "        [ 31,  37],\n",
              "        [ 92, 108],\n",
              "        [ 59,  70],\n",
              "        [ 80,  94],\n",
              "        [124, 146],\n",
              "        [ 31,  37],\n",
              "        [ 92, 108],\n",
              "        [ 59,  70],\n",
              "        [ 80,  94],\n",
              "        [124, 146],\n",
              "        [ 31,  37],\n",
              "        [ 92, 108]], dtype=torch.int32)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = model(inputs)\n",
        "preds.int()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrPiIPFWjdZ",
        "outputId": "d94584a2-c3fb-4110-9861-372fe403b3c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWrn16GAqCTt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
